+++
title = "Gaussian affinity for max-margin class imbalanced learning"
date = "2019-12-01"
authors = ["M. Hayat","S. Khan","S. Waqas Zamir","J. Shen","L. Shao"]
tags = []
publication_types = ["1"]
publication = "_Proceedings of the IEEE International Conference on Computer Vision_"
publication_short = ""
summary = "<p style='text-align: justify;'> Real-world object classes appear in imbalanced ratios. This poses a significant challenge for classifiers which get biased towards frequent classes. We hypothesize that improving the generalization capability of a classifier should improve learning on imbalanced datasets. Here, we introduce the first hybrid loss function that jointly performs classification and clustering in a single formulation. Our approach is based on an 'affinity measure' in Euclidean space that leads to the following benefits: (1) direct enforcement of maximum margin constraints on classification boundaries, (2) a tractable way to ensure uniformly spaced and equidistant cluster centers, (3) flexibility to learn multiple class prototypes to support diversity and discriminability in feature space. Our extensive experiments demonstrate the significant performance improvements on visual classification and verification tasks on multiple imbalanced datasets. The proposed loss can easily be plugged in any deep architecture as a differentiable block and demonstrates robustness against different levels of data imbalance and corrupted labels. </p>"
featured = true
projects = []
slides = ""
url_pdf = "/publication/hayat2019gaussian/manuscript.pdf"
url_code = ""
url_dataset = ""
url_poster = ""
url_slides = ""
url_source = ""
url_video = ""
math = true
highlight = true
[image]
image = ""
caption = ""
+++

